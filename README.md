#Shane Kennedy's Machine Learning Portfolio

## About Me

I am a fourth-year student at SETU, Carlow, with a strong passion for Machine Learning. My interests in Machine Learning include Object Identification, Image Processing, and Chatbots. I am at the beginning of my Machine Learning journey but enthusiastic about learning and completing projects to further my skills and knowledge.

## Skills and Experience

#### Infrastructures
- Cloud Computing (AWS, PythonAnywhere)
- Docker and Containerization
- Virtualization (VMware, VirtualBox)

#### Data and Data Storage Technologies
- SQL and Relational Databases (Teradata, MariaDB, Microsoft SQL Server)
- NoSQL Databases (MongoDB)
- Data Warehousing (Teradata)
- Data Pipelines (MongoDB Aggregations, IBM Datastage, Tableau Prep)

#### Data Analysis
- Data Visualisation (Tableau)

#### Programming Languages
- Python (BeautiSoup, Pandas)
- Java
- JavaScript
- React, React native
- C++, C
- X86 Assembly

#### Machine Learning Algorithms
- Linear Regression
- Decision Trees and Random Forest
- Neural Networks (Deep Learning)
- Support Vector Machines

#### Other Technical Skills
- Git and Version Control
- Linux/Unix Systems
- Web Development (HTML, CSS, Flask, Anvil, React)

### Current Projects

#### Project: Automated Data Scraping from Weather Website and storage to a local database

##### Introduction

In a world increasingly reliant on data-driven decision-making, access to accurate and up-to-date weather information is crucial for various applications, from agriculture to logistics and personal planning. This project aims to hone my skills in data scraping data from a website. This data will be in an unstructured state so data cleaning and transformation skills will also be required. This process of will retrieve, clean and transform the data automatically and then store it in a local database for easy access and analysis.

##### Project Overview

**Objective**: The primary goal of this project is to automate the retrieval of weather data from a selected weather website and establish a local database to store this data efficiently.

**Key Components**:

1. **Web Scraping**: We will develop a web scraping script using the BeautiSoup library to extract the weather data (e.g., temperature, humidity, wind speed, and conditions) from the weather website. This script will run at specified intervals to keep the data up to date.

2. **Data Transformation**: Once the data is scraped, it will be transformed and structured into a format suitable for database storage. This step may involve data cleaning and formatting.

3. **Local Database**: We will set up a local database using SQLite to store the scraped weather data. The database schema will be designed to accommodate the specific data attributes.

4. **Automation**: The entire process will be automated, with scheduled runs of the web scraping script to keep the database updated with the latest weather information.

5. **Data Access**: Users will be able to access and query the local database for weather information.

**Benefits**:

- **Data Availability**: Weather data will be readily available in a local database, reducing the need for real-time API calls to external sources.

- **Data Analysis**: With data stored locally, I intend to use this data in future projects.


- GitHub Repository: [Link to GitHub Repository](https://github.com/yourusername/image-classification-project)
- Feel free to reach out if you'd like more details or have any questions about my projects or skills!